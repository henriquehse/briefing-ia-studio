import { GoogleGenerativeAI } from '@google/generative-ai';
import { NextRequest, NextResponse } from 'next/server';

export const runtime = 'edge';

export async function POST(request: NextRequest) {
  try {
    const { messages, references } = await request.json();

    if (!messages || messages.length === 0) {
      return NextResponse.json(
        { error: 'Mensagens sÃ£o obrigatÃ³rias' },
        { status: 400 }
      );
    }

    const apiKey = process.env.GEMINI_API_KEY;
    
    if (!apiKey) {
      return NextResponse.json(
        { error: 'API Key do Gemini nÃ£o configurada' },
        { status: 500 }
      );
    }

    const genAI = new GoogleGenerativeAI(apiKey);
    const model = genAI.getGenerativeModel({ model: 'gemini-2.5-flash' });

    const referencesContext = references && references.length > 0
      ? `\n\nREFERÃŠNCIAS FORNECIDAS:\n${references.map((ref: any, i: number) => 
          `ReferÃªncia ${i + 1} - ${ref.name}:\n${ref.content}`
        ).join('\n\n')}\n\n`
      : '';

    // System prompt sem markdown
    const systemPrompt = `VocÃª Ã© um assistente especialista em criar briefings e documentaÃ§Ãµes profissionais.

IMPORTANTE - REGRAS DE FORMATAÃ‡ÃƒO:
- NÃƒO use markdown na conversa (sem **, ##, ###, -, *, >, etc)
- Escreva em texto puro e limpo, como numa conversa natural
- Use apenas emojis ocasionais para dar vida Ã  conversa
- Quebre linhas normalmente quando necessÃ¡rio
- Seja conversacional, amigÃ¡vel e direto

SUAS CAPACIDADES:
- Fazer perguntas estratÃ©gicas para entender melhor o projeto
- Sugerir pesquisas na internet quando necessÃ¡rio
- Incorporar referÃªncias fornecidas pelo usuÃ¡rio
- Manter o contexto de toda a conversa
- Ao final, consolidar tudo em um documento profissional (aÃ­ sim com markdown)

DIRETRIZES DE CONVERSA:
- Seja natural e amigÃ¡vel
- FaÃ§a perguntas especÃ­ficas e relevantes
- Se o usuÃ¡rio mencionar algo vago, peÃ§a detalhes
- Quando tiver informaÃ§Ãµes suficientes, ofereÃ§a gerar o briefing final
- Mantenha sempre o contexto de toda a conversa anterior

${referencesContext}

LEMBRE-SE: Na conversa seja natural e limpo. O markdown sÃ³ serÃ¡ usado no documento final que o usuÃ¡rio vai baixar.`;

    const chatHistory = messages.slice(0, -1).map((msg: any) => ({
      role: msg.role === 'user' ? 'user' : 'model',
      parts: [{ text: msg.content }],
    }));

    const lastMessage = messages[messages.length - 1];

    const chat = model.startChat({
      history: [
        {
          role: 'user',
          parts: [{ text: systemPrompt }],
        },
        {
          role: 'model',
          parts: [{ text: 'OlÃ¡! ðŸ‘‹ Estou aqui para ajudar vocÃª a criar um briefing profissional. Vamos comeÃ§ar!' }],
        },
        ...chatHistory,
      ],
    });

    const result = await chat.sendMessageStream(lastMessage.content);

    const encoder = new TextEncoder();
    const stream = new ReadableStream({
      async start(controller) {
        try {
          for await (const chunk of result.stream) {
            const text = chunk.text();
            controller.enqueue(encoder.encode(`data: ${JSON.stringify({ text })}\n\n`));
          }
          controller.enqueue(encoder.encode('data: [DONE]\n\n'));
          controller.close();
        } catch (error) {
          controller.error(error);
        }
      },
    });

    return new Response(stream, {
      headers: {
        'Content-Type': 'text/event-stream',
        'Cache-Control': 'no-cache',
        'Connection': 'keep-alive',
      },
    });

  } catch (error: any) {
    console.error('Erro no chat:', error);
    return NextResponse.json(
      { 
        error: 'Erro ao processar mensagem',
        details: error?.message || 'Erro desconhecido'
      },
      { status: 500 }
    );
  }
}
